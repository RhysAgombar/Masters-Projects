{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_embeddings(emb_file, vocab):\n",
    "\n",
    "    vocab = [v.lower() for v in vocab]\n",
    "\n",
    "    embeds = {}\n",
    "    for line in open(emb_file, 'r', encoding=\"utf8\"):\n",
    "        line = line.strip().split(' ')\n",
    "        \n",
    "        key = line[0]\n",
    "        \n",
    "        line = [float(i) for i in line[1:len(line)]]\n",
    "        \n",
    "        wvec = torch.Tensor(line)#map(float, line[1:]))\n",
    "        embeds[key] = wvec\n",
    "        \n",
    "    embeds = [embeds[k] for k in vocab]\n",
    "    embeds = torch.stack(embeds)\n",
    "    print('loaded embeddings', embeds.size())\n",
    "\n",
    "    return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raven\\Desktop\\Masters-Projects\\Visual Computing Lab\\ResNetTest\\AttrOpClassification\\Dataset\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.getcwd() + \"\\Dataset\"\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'Seasoned': transforms.Compose([ # Dataset for Training\n",
    "        transforms.Resize(224),\n",
    "        #transforms.RandomResizedCrop(224), # Random Resized Crop is not well suited for this database\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'Sliced': transforms.Compose([ # Dataset for Training\n",
    "        transforms.Resize(224),\n",
    "        #transforms.RandomResizedCrop(224), # Random Resized Crop is not well suited for this database\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'Whole': transforms.Compose([ # Dataset for Training\n",
    "        transforms.Resize(224),\n",
    "        #transforms.RandomResizedCrop(224), # Random Resized Crop is not well suited for this database\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators = ['Seasoned', 'Sliced', 'Whole']\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in operators}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=10,\n",
    "                                             shuffle=True, num_workers=1)\n",
    "              for x in operators}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in operators}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = ['Meat', 'Potato', 'Eggs', 'Carrot', 'Apple', 'Onion', 'Cauliflower']\n",
    "operators = ['Seasoned', 'Sliced', 'Whole']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded embeddings torch.Size([7, 300])\n"
     ]
    }
   ],
   "source": [
    "objEmb = load_word_embeddings(\"glove\\glove.6B.300d.txt\", objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded embeddings torch.Size([3, 300])\n"
     ]
    }
   ],
   "source": [
    "opEmb = load_word_embeddings(\"glove\\glove.6B.300d.txt\", operators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Problems Start\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module): ## The issue is somewhere in here\n",
    "    def __init__(self, inp_dim, out_dim, num_layers=1, relu=True, bias=True):\n",
    "        super(MLP, self).__init__()\n",
    "        mod = []\n",
    "        for L in range(num_layers-1):\n",
    "            mod.append(nn.Linear(inp_dim, inp_dim, bias=bias))\n",
    "            mod.append(nn.ReLU(True))\n",
    "\n",
    "        mod.append(nn.Linear(inp_dim, out_dim, bias=bias))\n",
    "        if relu:\n",
    "            mod.append(nn.ReLU(True))\n",
    "\n",
    "        self.mod = nn.Sequential(*mod)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.mod(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrOpModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttrOpModel, self).__init__()\n",
    "        \n",
    "        self.image_embedder = MLP(512, 300) # 512 image features embedded into 300\n",
    "        self.attr_ops = nn.ParameterList([nn.Parameter(torch.eye(300)) for _ in range(len(operators))])\n",
    "        self.obj_embedder = nn.Embedding(len(objects), 300)     \n",
    "        \n",
    "        pretrained_weight = load_word_embeddings('glove/glove.6B.300d.txt', objects)\n",
    "        self.obj_embedder.weight.data.copy_(pretrained_weight)\n",
    "\n",
    "        self.inverse_cache = {}\n",
    "        \n",
    "    def apply_op(self, obj, op):\n",
    "        out = torch.bmm(obj.view(1,1,300), op.view(1,300,300))\n",
    "        out = F.relu(out).view(300)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "    def train_forward(self, img, obj_label, pos_op_label, neg_obj, neg_op_label):\n",
    "        anchor = self.image_embedder(img) ## This is where the issue is    \n",
    "        #anchor = torch.zeros(1, 300)\n",
    "        \n",
    "        obj_emb = self.obj_embedder(torch.tensor(objects.index(obj_label), dtype=torch.long))\n",
    "        pos_op = self.attr_ops[operators.index(pos_op_label)]\n",
    "        positive = self.apply_op(obj_emb, pos_op)\n",
    "\n",
    "        neg_obj_emb = self.obj_embedder(torch.tensor(objects.index(neg_obj), dtype=torch.long))\n",
    "        neg_op = self.attr_ops[operators.index(neg_op_label)]\n",
    "        negative = self.apply_op(neg_obj_emb, neg_op)\n",
    "        \n",
    "        triplet_loss = nn.TripletMarginLoss(margin=0.5, p=2)\n",
    "        loss = triplet_loss(anchor, positive, negative)\n",
    "        return loss\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Problems End\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded embeddings torch.Size([7, 300])\n"
     ]
    }
   ],
   "source": [
    "model = AttrOpModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neg_pairs(pp):\n",
    "    np = []\n",
    "    for i in pp:\n",
    "        ls = []\n",
    "        for j in operators:\n",
    "            for k in objects:\n",
    "                if j != i[0] and k != i[1]:\n",
    "                    ls.append([j,k])\n",
    "        np.append(ls)\n",
    "    return np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Sliced', 'Potato'], ['Sliced', 'Eggs'], ['Sliced', 'Carrot'], ['Sliced', 'Apple'], ['Sliced', 'Onion'], ['Sliced', 'Cauliflower'], ['Whole', 'Potato'], ['Whole', 'Eggs'], ['Whole', 'Carrot'], ['Whole', 'Apple'], ['Whole', 'Onion'], ['Whole', 'Cauliflower']], [['Seasoned', 'Meat'], ['Seasoned', 'Potato'], ['Seasoned', 'Eggs'], ['Seasoned', 'Carrot'], ['Seasoned', 'Onion'], ['Seasoned', 'Cauliflower'], ['Whole', 'Meat'], ['Whole', 'Potato'], ['Whole', 'Eggs'], ['Whole', 'Carrot'], ['Whole', 'Onion'], ['Whole', 'Cauliflower']]]\n"
     ]
    }
   ],
   "source": [
    "pp = [['Seasoned', 'Meat'], ['Sliced', 'Apple']]\n",
    "print(get_neg_pairs(pp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_params = [param for name, param in model.named_parameters() if 'attr_op' in name and param.requires_grad]\n",
    "other_params = [param for name, param in model.named_parameters() if 'attr_op' not in name and param.requires_grad]\n",
    "optim_params = [{'params':attr_params, 'lr':1e-05}, {'params':other_params}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(optim_params, lr=1e-04, weight_decay=5e-5)\n",
    "feat_extractor = models.resnet18(pretrained=True)\n",
    "feat_extractor.fc = nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "inApple = []\n",
    "while len(inApple) < 2:\n",
    "    inputs, classes = next(iter(dataloaders['Whole']))\n",
    "    for i in range(len(inputs)):\n",
    "        if classes.data[i] == 0:\n",
    "            inApple.append(inputs[i])\n",
    "            \n",
    "af = [] # Apple Features\n",
    "for i in range(len(inApple)):\n",
    "    af.append(feat_extractor(inApple[i].unsqueeze_(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Variable(af[0])\n",
    "obj_label = \"Apple\"\n",
    "pos_op_label = \"Whole\"\n",
    "neg_obj = \"Meat\"\n",
    "neg_op_label = \"Sliced\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# \"Training\" On a single item to test if the functions actually work\n",
    "model.train()\n",
    "loss = 0.0\n",
    "for i in range(0,12):\n",
    "    loss = model.train_forward(img, obj_label, pos_op_label, neg_obj, neg_op_label)\n",
    "    print(loss)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 11\n",
    "loss = 0\n",
    "for op in operators: # for each operator...\n",
    "    class_names = image_datasets[op].classes\n",
    "    imgs = []\n",
    "    pp = []\n",
    "    np = []\n",
    "    \n",
    "    while len(imgs) < batch_size:\n",
    "        inputs, classes = next(iter(dataloaders[op]))  # Gather a set of images and classes from them\n",
    "        \n",
    "        for i in inputs:\n",
    "            imgs.append(feat_extractor(i.unsqueeze_(0)))\n",
    "            if(len(imgs) == batch_size):\n",
    "                break\n",
    "        for i in classes:\n",
    "            pp.append([op, class_names[i]])\n",
    "            if(len(pp) == batch_size):\n",
    "                break\n",
    "\n",
    "    np = get_neg_pairs(pp)\n",
    "    #for i in range(len(imgs)):\n",
    "    #    for j in np[i]:               model.train_forward(imgs[i], pp[i][1], pp[i][0], j[1], j[0])\n",
    "    loss = model.train_forward(imgs[i], pp[i][1], pp[i][0], j[1], j[0])\n",
    "    print(loss)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
