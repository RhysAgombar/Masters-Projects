{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_embeddings(emb_file, vocab):\n",
    "\n",
    "    vocab = [v.lower() for v in vocab]\n",
    "\n",
    "    embeds = {}\n",
    "    for line in open(emb_file, 'r', encoding=\"utf8\"):\n",
    "        line = line.strip().split(' ')\n",
    "        \n",
    "        key = line[0]\n",
    "        \n",
    "        line = [float(i) for i in line[1:len(line)]]\n",
    "        \n",
    "        wvec = torch.Tensor(line)#map(float, line[1:]))\n",
    "        embeds[key] = wvec\n",
    "        \n",
    "    embeds = [embeds[k] for k in vocab]\n",
    "    embeds = torch.stack(embeds)\n",
    "    print('loaded embeddings', embeds.size())\n",
    "\n",
    "    return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raven\\Desktop\\Masters-Projects\\Visual Computing Lab\\ResNetTest\\AttrOpClassification\\Dataset\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.getcwd() + \"\\Dataset\"\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'Seasoned': transforms.Compose([ # Dataset for Training\n",
    "        transforms.Resize(224),\n",
    "        #transforms.RandomResizedCrop(224), # Random Resized Crop is not well suited for this database\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'Sliced': transforms.Compose([ # Dataset for Training\n",
    "        transforms.Resize(224),\n",
    "        #transforms.RandomResizedCrop(224), # Random Resized Crop is not well suited for this database\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'Whole': transforms.Compose([ # Dataset for Training\n",
    "        transforms.Resize(224),\n",
    "        #transforms.RandomResizedCrop(224), # Random Resized Crop is not well suited for this database\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators = ['Seasoned', 'Sliced', 'Whole']\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in operators}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=10,\n",
    "                                             shuffle=True, num_workers=10)\n",
    "              for x in operators}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in operators}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Meat', 'Potato']\n",
      "['Apple', 'Carrot', 'Meat', 'Onion', 'Potato']\n",
      "['Apple', 'Carrot', 'Cauliflower', 'Eggs', 'Meat', 'Potato']\n",
      "['Potato', 'Onion', 'Eggs', 'Carrot', 'Cauliflower', 'Apple', 'Meat']\n"
     ]
    }
   ],
   "source": [
    "objects = []\n",
    "for i in operators:\n",
    "    class_names = image_datasets[i].classes\n",
    "    print(class_names)\n",
    "    for j in class_names:\n",
    "        objects.append(j)\n",
    "\n",
    "objects = list(set(objects))\n",
    "print(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Base Objects\n",
    "# Apply Operator To Them\n",
    "# Compare the distance between that object-attr pair and the generated one,\n",
    "#      vs the generated one and an unrelated object-attr pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Whole Apple for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inApple = []\n",
    "while len(inApple) < 5:\n",
    "    inputs, classes = next(iter(dataloaders['Whole']))\n",
    "    #print(classes)\n",
    "    #print(classes.data[0])\n",
    "    for i in range(len(inputs)):\n",
    "        if classes.data[i] == 0:\n",
    "            inApple.append(inputs[i])\n",
    "#print(inApple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Sliced Apple for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inSApple = []\n",
    "while len(inSApple) < 5:\n",
    "    inputs, classes = next(iter(dataloaders['Sliced']))\n",
    "    #print(classes)\n",
    "    #print(classes.data[0])\n",
    "    for i in range(len(inputs)):\n",
    "        if classes.data[i] == 0:\n",
    "            inSApple.append(inputs[i])\n",
    "#print(inSApple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Seasoned Meat for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inSeMeat = []\n",
    "while len(inSeMeat) < 5:\n",
    "    inputs, classes = next(iter(dataloaders['Seasoned']))\n",
    "    #print(classes)\n",
    "    #print(classes.data[0])\n",
    "    for i in range(len(inputs)):\n",
    "        if classes.data[i] == 0:\n",
    "            inSeMeat.append(inputs[i])\n",
    "#print(inSeMeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_extractor = models.resnet18(pretrained=True)\n",
    "feat_extractor.fc = nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = [] # Apple Features\n",
    "for i in range(len(inApple)):\n",
    "    af.append(feat_extractor(inApple[i].unsqueeze_(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "asf = [] # Apple Sliced Features\n",
    "for i in range(len(inSApple)):\n",
    "    asf.append(feat_extractor(inSApple[i].unsqueeze_(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "msef = [] # Meat Seasoned Features\n",
    "for i in range(len(inSeMeat)):\n",
    "    msef.append(feat_extractor(inSeMeat[i].unsqueeze_(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "print(msef[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Triplet Loss = Max(0, (distance between resnet and Attribute applied to object), \n",
    "# (distance between resnet and negative Attribute applied to negative object))\n",
    "\n",
    "\n",
    "\n",
    "# Need to embed object words\n",
    "# Need to embed attributes\n",
    "# use bmm to multiply the two\n",
    "# Compare distance between ... ^^^\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded embeddings torch.Size([7, 300])\n"
     ]
    }
   ],
   "source": [
    "objEmb = load_word_embeddings(\"glove\\glove.6B.300d.txt\", objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded embeddings torch.Size([3, 300])\n"
     ]
    }
   ],
   "source": [
    "opEmb = load_word_embeddings(\"glove\\glove.6B.300d.txt\", operators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300])\n"
     ]
    }
   ],
   "source": [
    "test = torch.randn(300, 300)\n",
    "out = torch.bmm(objEmb[0].view(1,1,300), test.view(1,300,300))\n",
    "out = F.relu(out).view(300)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = ['Meat', 'Potato', 'Eggs', 'Carrot', 'Apple', 'Onion', 'Cauliflower']\n",
    "operators = ['Seasoned', 'Sliced', 'Whole']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, inp_dim, out_dim, num_layers=1, relu=True, bias=True):\n",
    "        super(MLP, self).__init__()\n",
    "        mod = []\n",
    "        for L in range(num_layers-1):\n",
    "            mod.append(nn.Linear(inp_dim, inp_dim, bias=bias))\n",
    "            mod.append(nn.ReLU(True))\n",
    "\n",
    "        mod.append(nn.Linear(inp_dim, out_dim, bias=bias))\n",
    "        if relu:\n",
    "            mod.append(nn.ReLU(True))\n",
    "\n",
    "        self.mod = nn.Sequential(*mod)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.mod(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrOpModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttrOpModel, self).__init__()\n",
    "        self.image_embedder = MLP(512, 300) # 512 image features embedded into 50\n",
    "        self.attr_ops = nn.ParameterList([nn.Parameter(torch.eye(300)) for _ in range(len(operators))])\n",
    "        self.obj_embedder = nn.Embedding(len(objects), 300)     \n",
    "        \n",
    "        pretrained_weight = load_word_embeddings('glove/glove.6B.300d.txt', objects)\n",
    "        self.obj_embedder.weight.data.copy_(pretrained_weight)\n",
    "\n",
    "        self.inverse_cache = {}\n",
    "        \n",
    "        \n",
    "    def apply_op(self, obj, op):\n",
    "        out = torch.bmm(obj.view(1,1,300), op.view(1,300,300))\n",
    "        out = F.relu(out).view(300)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "    def train_forward(self, img, obj_label, pos_op_label, neg_obj, neg_op_label):\n",
    "        anchor = self.image_embedder(img)\n",
    "\n",
    "        obj_emb = self.obj_embedder(torch.tensor(objects.index(obj_label), dtype=torch.long))\n",
    "        pos_op = self.attr_ops[operators.index(pos_op_label)]\n",
    "        positive = self.apply_op(obj_emb, pos_op)\n",
    "\n",
    "        neg_obj_emb = self.obj_embedder(torch.tensor(objects.index(neg_obj), dtype=torch.long))\n",
    "        neg_op = self.attr_ops[operators.index(neg_op_label)]\n",
    "        negative = self.apply_op(neg_obj_emb, neg_op)\n",
    "\n",
    "        loss_triplet = F.triplet_margin_loss(anchor, positive, negative, margin=0.5)\n",
    "        return loss_triplet\n",
    "        \n",
    "    #def forward(self, img, obj_label, pos_op_label, neg_obj, neg_op_label):\n",
    "    #    if self.training:\n",
    "    #        loss, pred = self.train_forward(img, obj_label, pos_op_label, neg_obj, neg_op_label)\n",
    "    #    else:\n",
    "    #       print(\"potato\") ## Val forward\n",
    "    #    self.inverse_cache = {}\n",
    "    #    return loss, pred\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded embeddings torch.Size([7, 300])\n"
     ]
    }
   ],
   "source": [
    "model = AttrOpModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Seasoned', 'Sliced', 'Whole']\n",
      "['Meat', 'Potato', 'Eggs', 'Carrot', 'Apple', 'Onion', 'Cauliflower']\n"
     ]
    }
   ],
   "source": [
    "print(operators)\n",
    "print(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-5fa45b34583d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_op_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_op_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "model.train_forward(img, obj_label, pos_op_label, neg_obj, neg_op_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neg_pairs(pp):\n",
    "    np = []\n",
    "    for i in pp:\n",
    "        ls = []\n",
    "        for j in operators:\n",
    "            for k in objects:\n",
    "                if j != i[0] and k != i[1]:\n",
    "                    ls.append([j,k])\n",
    "        np.append(ls)\n",
    "    return np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Sliced', 'Potato'], ['Sliced', 'Eggs'], ['Sliced', 'Carrot'], ['Sliced', 'Apple'], ['Sliced', 'Onion'], ['Sliced', 'Cauliflower'], ['Whole', 'Potato'], ['Whole', 'Eggs'], ['Whole', 'Carrot'], ['Whole', 'Apple'], ['Whole', 'Onion'], ['Whole', 'Cauliflower']], [['Seasoned', 'Meat'], ['Seasoned', 'Potato'], ['Seasoned', 'Eggs'], ['Seasoned', 'Carrot'], ['Seasoned', 'Onion'], ['Seasoned', 'Cauliflower'], ['Whole', 'Meat'], ['Whole', 'Potato'], ['Whole', 'Eggs'], ['Whole', 'Carrot'], ['Whole', 'Onion'], ['Whole', 'Cauliflower']]]\n"
     ]
    }
   ],
   "source": [
    "pp = [['Seasoned', 'Meat'], ['Sliced', 'Apple']]\n",
    "print(get_neg_pairs(pp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_params = [param for name, param in model.named_parameters() if 'attr_op' in name and param.requires_grad]\n",
    "other_params = [param for name, param in model.named_parameters() if 'attr_op' not in name and param.requires_grad]\n",
    "optim_params = [{'params':attr_params, 'lr':1e-05}, {'params':other_params}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " optimizer = optim.Adam(optim_params, lr=1e-04, weight_decay=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'o' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-55d32e5c4c7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m#for i in range(len(imgs)):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#    for j in np[i]:               model.train_forward(imgs[i], pp[i][1], pp[i][0], j[1], j[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-536280df7229>\u001b[0m in \u001b[0;36mtrain_forward\u001b[1;34m(self, img, obj_label, pos_op_label, neg_obj, neg_op_label)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mpositive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mneg_obj_emb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj_embedder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mneg_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattr_ops\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moperators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg_op_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mnegative\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg_obj_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'o' is not in list"
     ]
    }
   ],
   "source": [
    "batch_size = 11\n",
    "loss = 0\n",
    "for op in operators: # for each operator...\n",
    "    class_names = image_datasets[op].classes\n",
    "    imgs = []\n",
    "    pp = []\n",
    "    np = []\n",
    "    \n",
    "    while len(imgs) < batch_size:\n",
    "        inputs, classes = next(iter(dataloaders[op]))  # Gather a set of images and classes from them\n",
    "        \n",
    "        for i in inputs:\n",
    "            imgs.append(feat_extractor(i.unsqueeze_(0)))\n",
    "            if(len(imgs) == batch_size):\n",
    "                break\n",
    "        for i in classes:\n",
    "            pp.append([op, class_names[i]])\n",
    "            if(len(pp) == batch_size):\n",
    "                break\n",
    "\n",
    "    np = get_neg_pairs(pp)\n",
    "    #for i in range(len(imgs)):\n",
    "    #    for j in np[i]:               model.train_forward(imgs[i], pp[i][1], pp[i][0], j[1], j[0])\n",
    "    loss = model.train_forward(imgs[i], pp[i][1], pp[i][0], j[1], j[0])\n",
    "    print(loss)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_params = [param for name, param in model.named_parameters() if 'attr_op' in name and param.requires_grad]\n",
    "other_params = [param for name, param in model.named_parameters() if 'attr_op' not in name and param.requires_grad]\n",
    "optim_params = [{'params':attr_params, 'lr':1e-05}, {'params':other_params}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-04, weight_decay=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Variable(af[0])\n",
    "obj_label = \"Apple\"\n",
    "pos_op_label = \"Whole\"\n",
    "neg_obj = \"Meat\"\n",
    "neg_op_label = \"Sliced\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "model.zero_grad()\n",
    "loss = model.train_forward(img, obj_label, pos_op_label, neg_obj, neg_op_label)\n",
    "print(loss)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inApple = []\n",
    "while len(inApple) < 5:\n",
    "    inputs, classes = next(iter(dataloaders['Whole']))\n",
    "    #print(classes)\n",
    "    #print(classes.data[0])\n",
    "    for i in range(len(inputs)):\n",
    "        if classes.data[i] == 0:\n",
    "            inApple.append(inputs[i])\n",
    "#print(inApple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = [] # Apple Features\n",
    "for i in range(len(inApple)):\n",
    "    af.append(feat_extractor(inApple[i].unsqueeze_(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
