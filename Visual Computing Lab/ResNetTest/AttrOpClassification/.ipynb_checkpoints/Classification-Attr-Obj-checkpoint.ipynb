{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_embeddings(emb_file, vocab):\n",
    "\n",
    "    vocab = [v.lower() for v in vocab]\n",
    "\n",
    "    embeds = {}\n",
    "    for line in open(emb_file, 'r', encoding=\"utf8\"):\n",
    "        line = line.strip().split(' ')\n",
    "        \n",
    "        key = line[0]\n",
    "        \n",
    "        line = [float(i) for i in line[1:len(line)]]\n",
    "        \n",
    "        wvec = torch.Tensor(line)#map(float, line[1:]))\n",
    "        embeds[key] = wvec\n",
    "        \n",
    "    embeds = [embeds[k] for k in vocab]\n",
    "    embeds = torch.stack(embeds)\n",
    "    print('loaded embeddings', embeds.size())\n",
    "\n",
    "    return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raven\\Desktop\\Masters-Projects\\Visual Computing Lab\\ResNetTest\\AttrOpClassification\\Dataset\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.getcwd() + \"\\Dataset\"\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'Seasoned': transforms.Compose([ # Dataset for Training\n",
    "        transforms.Resize(224),\n",
    "        #transforms.RandomResizedCrop(224), # Random Resized Crop is not well suited for this database\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'Sliced': transforms.Compose([ # Dataset for Training\n",
    "        transforms.Resize(224),\n",
    "        #transforms.RandomResizedCrop(224), # Random Resized Crop is not well suited for this database\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'Whole': transforms.Compose([ # Dataset for Training\n",
    "        transforms.Resize(224),\n",
    "        #transforms.RandomResizedCrop(224), # Random Resized Crop is not well suited for this database\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators = ['Seasoned', 'Sliced', 'Whole']\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in operators}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=10,\n",
    "                                             shuffle=True, num_workers=10)\n",
    "              for x in operators}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in operators}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Meat', 'Potato']\n",
      "['Apple', 'Carrot', 'Meat', 'Onion', 'Potato']\n",
      "['Apple', 'Carrot', 'Cauliflower', 'Eggs', 'Meat', 'Potato']\n",
      "['Onion', 'Potato', 'Carrot', 'Meat', 'Eggs', 'Cauliflower', 'Apple']\n"
     ]
    }
   ],
   "source": [
    "objects = []\n",
    "for i in operators:\n",
    "    class_names = image_datasets[i].classes\n",
    "    print(class_names)\n",
    "    for j in class_names:\n",
    "        objects.append(j)\n",
    "\n",
    "objects = list(set(objects))\n",
    "print(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Base Objects\n",
    "# Apply Operator To Them\n",
    "# Compare the distance between that object-attr pair and the generated one,\n",
    "#      vs the generated one and an unrelated object-attr pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Whole Apple for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inApple = []\n",
    "while len(inApple) < 5:\n",
    "    inputs, classes = next(iter(dataloaders['Whole']))\n",
    "    #print(classes)\n",
    "    #print(classes.data[0])\n",
    "    for i in range(len(inputs)):\n",
    "        if classes.data[i] == 0:\n",
    "            inApple.append(inputs[i])\n",
    "#print(inApple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Sliced Apple for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inSApple = []\n",
    "while len(inSApple) < 5:\n",
    "    inputs, classes = next(iter(dataloaders['Sliced']))\n",
    "    #print(classes)\n",
    "    #print(classes.data[0])\n",
    "    for i in range(len(inputs)):\n",
    "        if classes.data[i] == 0:\n",
    "            inSApple.append(inputs[i])\n",
    "#print(inSApple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Seasoned Meat for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inSeMeat = []\n",
    "while len(inSeMeat) < 5:\n",
    "    inputs, classes = next(iter(dataloaders['Seasoned']))\n",
    "    #print(classes)\n",
    "    #print(classes.data[0])\n",
    "    for i in range(len(inputs)):\n",
    "        if classes.data[i] == 0:\n",
    "            inSeMeat.append(inputs[i])\n",
    "#print(inSeMeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_extractor = models.resnet18(pretrained=True)\n",
    "feat_extractor.fc = nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = [] # Apple Features\n",
    "for i in range(len(inApple)):\n",
    "    af.append(feat_extractor(inApple[i].unsqueeze_(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "asf = [] # Apple Sliced Features\n",
    "for i in range(len(inSApple)):\n",
    "    asf.append(feat_extractor(inSApple[i].unsqueeze_(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "msef = [] # Meat Seasoned Features\n",
    "for i in range(len(inSeMeat)):\n",
    "    msef.append(feat_extractor(inSeMeat[i].unsqueeze_(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "print(msef[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Triplet Loss = Max(0, (distance between resnet and Attribute applied to object), \n",
    "# (distance between resnet and negative Attribute applied to negative object))\n",
    "\n",
    "\n",
    "\n",
    "# Need to embed object words\n",
    "# Need to embed attributes\n",
    "# use bmm to multiply the two\n",
    "# Compare distance between ... ^^^\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded embeddings torch.Size([7, 300])\n"
     ]
    }
   ],
   "source": [
    "objEmb = load_word_embeddings(\"glove\\glove.6B.300d.txt\", objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded embeddings torch.Size([3, 300])\n"
     ]
    }
   ],
   "source": [
    "opEmb = load_word_embeddings(\"glove\\glove.6B.300d.txt\", operators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300])\n"
     ]
    }
   ],
   "source": [
    "test = torch.randn(300, 300)\n",
    "out = torch.bmm(objEmb[0].view(1,1,300), test.view(1,300,300))\n",
    "out = F.relu(out).view(300)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = ['Meat', 'Potato', 'Eggs', 'Carrot', 'Apple', 'Onion', 'Cauliflower']\n",
    "operators = ['Seasoned', 'Sliced', 'Whole']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, inp_dim, out_dim, num_layers=1, relu=True, bias=True):\n",
    "        super(MLP, self).__init__()\n",
    "        mod = []\n",
    "        for L in range(num_layers-1):\n",
    "            mod.append(nn.Linear(inp_dim, inp_dim, bias=bias))\n",
    "            mod.append(nn.ReLU(True))\n",
    "\n",
    "        mod.append(nn.Linear(inp_dim, out_dim, bias=bias))\n",
    "        if relu:\n",
    "            mod.append(nn.ReLU(True))\n",
    "\n",
    "        self.mod = nn.Sequential(*mod)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.mod(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrOpModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttrOpModel, self).__init__()\n",
    "        self.image_embedder = MLP(512, 300) # 512 image features embedded into 50\n",
    "        self.attr_ops = nn.ParameterList([nn.Parameter(torch.eye(300)) for _ in range(len(operators))])\n",
    "        self.obj_embedder = nn.Embedding(len(objects), 300)     \n",
    "        \n",
    "        pretrained_weight = load_word_embeddings('glove/glove.6B.300d.txt', objects)\n",
    "        self.obj_embedder.weight.data.copy_(pretrained_weight)\n",
    "\n",
    "        self.inverse_cache = {}\n",
    "        \n",
    "        \n",
    "    def apply_op(self, obj, op):\n",
    "        out = torch.bmm(obj.view(1,1,300), op.view(1,300,300))\n",
    "        out = F.relu(out).view(300)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "    def train_forward(self, img, obj_label, pos_op_label, neg_obj, neg_op_label):\n",
    "        anchor = self.image_embedder(img)\n",
    "\n",
    "        obj_emb = self.obj_embedder(torch.tensor(objects.index(obj_label), dtype=torch.long))\n",
    "        pos_op = self.attr_ops[operators.index(pos_op_label)]\n",
    "        positive = self.apply_op(obj_emb, pos_op)\n",
    "\n",
    "        neg_obj_emb = self.obj_embedder(torch.tensor(objects.index(neg_obj), dtype=torch.long))\n",
    "        neg_op = self.attr_ops[operators.index(neg_op_label)]\n",
    "        negative = self.apply_op(neg_obj_emb, neg_op)\n",
    "\n",
    "        loss_triplet = F.triplet_margin_loss(anchor, positive, negative, margin=0.5)\n",
    "        print(loss_triplet)\n",
    "        \n",
    "    def forward(self, img, obj_label, pos_op_label, neg_obj, neg_op_label):\n",
    "        if self.training:\n",
    "            loss, pred = self.train_forward(img, obj_label, pos_op_label, neg_obj, neg_op_label)\n",
    "        else:\n",
    "           print(\"potato\") ## Val forward\n",
    "        self.inverse_cache = {}\n",
    "        return loss, pred\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded embeddings torch.Size([7, 300])\n"
     ]
    }
   ],
   "source": [
    "model = AttrOpModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Seasoned', 'Sliced', 'Whole']\n",
      "['Meat', 'Potato', 'Eggs', 'Carrot', 'Apple', 'Onion', 'Cauliflower']\n"
     ]
    }
   ],
   "source": [
    "print(operators)\n",
    "print(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = af[0]\n",
    "obj_label = \"Apple\"\n",
    "pos_op_label = \"Whole\"\n",
    "neg_obj = \"Meat\"\n",
    "neg_op_label = \"Sliced\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6139)\n"
     ]
    }
   ],
   "source": [
    "model.train_forward(img, obj_label, pos_op_label, neg_obj, neg_op_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neg_pairs(pp):\n",
    "    np = []\n",
    "    for i in pp:\n",
    "        ls = []\n",
    "        for j in operators:\n",
    "            for k in objects:\n",
    "                if j != i[0] and k != i[1]:\n",
    "                    ls.append([j,k])\n",
    "        np.append(ls)\n",
    "    return np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Sliced', 'Onion'], ['Sliced', 'Potato'], ['Sliced', 'Carrot'], ['Sliced', 'Eggs'], ['Sliced', 'Cauliflower'], ['Sliced', 'Apple'], ['Whole', 'Onion'], ['Whole', 'Potato'], ['Whole', 'Carrot'], ['Whole', 'Eggs'], ['Whole', 'Cauliflower'], ['Whole', 'Apple']], [['Seasoned', 'Onion'], ['Seasoned', 'Potato'], ['Seasoned', 'Carrot'], ['Seasoned', 'Meat'], ['Seasoned', 'Eggs'], ['Seasoned', 'Cauliflower'], ['Whole', 'Onion'], ['Whole', 'Potato'], ['Whole', 'Carrot'], ['Whole', 'Meat'], ['Whole', 'Eggs'], ['Whole', 'Cauliflower']]]\n"
     ]
    }
   ],
   "source": [
    "pp = [['Seasoned', 'Meat'], ['Sliced', 'Apple']]\n",
    "print(get_neg_pairs(pp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sliced', 'Onion']\n",
      "tensor(0.2666)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.3822)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.3019)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.1418)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.3815)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.2666)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.3822)\n",
      "['Whole', 'Carrot']\n",
      "tensor(0.3019)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.1418)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.3815)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.2499)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.3808)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.2926)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.1324)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.3801)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.2499)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.3808)\n",
      "['Whole', 'Carrot']\n",
      "tensor(0.2926)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.1324)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.3801)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.3621)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.3969)\n",
      "['Sliced', 'Meat']\n",
      "tensor(0.6041)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.2508)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.4885)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.3621)\n",
      "['Whole', 'Carrot']\n",
      "tensor(0.3969)\n",
      "['Whole', 'Meat']\n",
      "tensor(0.6041)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.2508)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.4885)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.2505)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.3766)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.2982)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.1311)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.3685)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.2505)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.3766)\n",
      "['Whole', 'Carrot']\n",
      "tensor(0.2982)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.1311)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.3685)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.2540)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.3681)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.2879)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.1293)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.3829)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.2540)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.3681)\n",
      "['Whole', 'Carrot']\n",
      "tensor(0.2879)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.1293)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.3829)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.2627)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.3911)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.3052)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.1570)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.3882)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.2627)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.3911)\n",
      "['Whole', 'Carrot']\n",
      "tensor(0.3052)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.1570)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.3882)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.2391)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.3776)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.2976)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.1319)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.3623)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.2391)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.3776)\n",
      "['Whole', 'Carrot']\n",
      "tensor(0.2976)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.1319)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.3623)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.2481)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.3784)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.2828)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.1362)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.3740)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.2481)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.3784)\n",
      "['Whole', 'Carrot']\n",
      "tensor(0.2828)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.1362)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.3740)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.2477)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.3805)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.2878)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.1275)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.3806)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.2477)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.3805)\n",
      "['Whole', 'Carrot']\n",
      "tensor(0.2878)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.1275)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.3806)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.2523)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.3776)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.3032)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.1276)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.3807)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.2523)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.3776)\n",
      "['Whole', 'Carrot']\n",
      "tensor(0.3032)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.1276)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.3807)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.2618)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.3990)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.3068)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.1611)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.3931)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.2618)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.3990)\n",
      "['Whole', 'Carrot']\n",
      "tensor(0.3068)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.1611)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.3931)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.4710)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.5993)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.7003)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.3378)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(1.00000e-02 *\n",
      "       5.7262)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.5795)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.4710)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.5993)\n",
      "['Whole', 'Meat']\n",
      "tensor(0.7003)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.3378)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(1.00000e-02 *\n",
      "       5.7262)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.5795)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.4498)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.5730)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.7123)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.3705)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(1.00000e-02 *\n",
      "       9.0220)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.5741)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.4498)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.5730)\n",
      "['Whole', 'Meat']\n",
      "tensor(0.7123)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.3705)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(1.00000e-02 *\n",
      "       9.0220)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.5741)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.3725)\n",
      "['Seasoned', 'Carrot']\n",
      "tensor(0.4136)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.6132)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.2448)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(1.00000e-04 *\n",
      "       1.1063)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.4885)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.3725)\n",
      "['Whole', 'Carrot']\n",
      "tensor(0.4136)\n",
      "['Whole', 'Meat']\n",
      "tensor(0.6132)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.2448)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(1.00000e-04 *\n",
      "       1.1063)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.4885)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.4569)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.5675)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.6908)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.3462)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(1.00000e-02 *\n",
      "       7.8007)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.5671)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.4569)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.5675)\n",
      "['Whole', 'Meat']\n",
      "tensor(0.6908)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.3462)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(1.00000e-02 *\n",
      "       7.8007)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.5671)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.3576)\n",
      "['Seasoned', 'Carrot']\n",
      "tensor(0.3928)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.6306)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.2712)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.4885)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.3576)\n",
      "['Whole', 'Carrot']\n",
      "tensor(0.3928)\n",
      "['Whole', 'Meat']\n",
      "tensor(0.6306)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.2712)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.4885)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.6388)\n",
      "['Seasoned', 'Carrot']\n",
      "tensor(0.5227)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.7436)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.3880)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(0.1302)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.6324)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.6388)\n",
      "['Whole', 'Carrot']\n",
      "tensor(0.5227)\n",
      "['Whole', 'Meat']\n",
      "tensor(0.7436)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.3880)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(0.1302)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.6324)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.4599)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.5759)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.6883)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.3468)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(1.00000e-02 *\n",
      "       7.4046)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.5639)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.4599)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.5759)\n",
      "['Whole', 'Meat']\n",
      "tensor(0.6883)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.3468)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(1.00000e-02 *\n",
      "       7.4046)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.5639)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.4693)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.5947)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.7206)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.3600)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(0.1018)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.5945)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.4693)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.5947)\n",
      "['Whole', 'Meat']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7206)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.3600)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(0.1018)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.5945)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.4627)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.5903)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.7092)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.3653)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(0.1022)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.5802)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.4627)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.5903)\n",
      "['Whole', 'Meat']\n",
      "tensor(0.7092)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.3653)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(0.1022)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.5802)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.4717)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.5787)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.6898)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.3452)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(1.00000e-02 *\n",
      "       8.2921)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.5831)\n",
      "['Whole', 'Onion']\n",
      "tensor(0.4717)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.5787)\n",
      "['Whole', 'Meat']\n",
      "tensor(0.6898)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.3452)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(1.00000e-02 *\n",
      "       8.2921)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.5831)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.6146)\n",
      "['Seasoned', 'Carrot']\n",
      "tensor(0.5207)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.7150)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.3686)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(0.1083)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.6143)\n",
      "['Whole', 'Potato']\n",
      "tensor(0.6146)\n",
      "['Whole', 'Carrot']\n",
      "tensor(0.5207)\n",
      "['Whole', 'Meat']\n",
      "tensor(0.7150)\n",
      "['Whole', 'Eggs']\n",
      "tensor(0.3686)\n",
      "['Whole', 'Cauliflower']\n",
      "tensor(0.1083)\n",
      "['Whole', 'Apple']\n",
      "tensor(0.6143)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.6084)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.7339)\n",
      "['Seasoned', 'Carrot']\n",
      "tensor(0.6520)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.8579)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(0.2245)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.7263)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.6084)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.7339)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.6520)\n",
      "['Sliced', 'Meat']\n",
      "tensor(0.8579)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.2245)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.7263)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.3767)\n",
      "['Seasoned', 'Carrot']\n",
      "tensor(0.4189)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.6131)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.2559)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.5101)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.3767)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.4189)\n",
      "['Sliced', 'Meat']\n",
      "tensor(0.6131)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.2559)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.5101)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.2820)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.3846)\n",
      "['Seasoned', 'Carrot']\n",
      "tensor(0.2948)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.1457)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.3886)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.2820)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.3846)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.2948)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.1457)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.3886)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.3864)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.5062)\n",
      "['Seasoned', 'Carrot']\n",
      "tensor(0.4320)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.6300)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.2762)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(1.00000e-03 *\n",
      "       6.3143)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.3864)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.5062)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.4320)\n",
      "['Sliced', 'Meat']\n",
      "tensor(0.6300)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.2762)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(1.00000e-03 *\n",
      "       6.3143)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.6307)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.7357)\n",
      "['Seasoned', 'Carrot']\n",
      "tensor(0.6522)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.8605)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(0.2203)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.7341)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.6307)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.7357)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.6522)\n",
      "['Sliced', 'Meat']\n",
      "tensor(0.8605)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.2203)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.7341)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.3710)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.4924)\n",
      "['Seasoned', 'Carrot']\n",
      "tensor(0.3920)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.6005)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.2542)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.3710)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.4924)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.3920)\n",
      "['Sliced', 'Meat']\n",
      "tensor(0.6005)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.2542)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.3770)\n",
      "['Seasoned', 'Carrot']\n",
      "tensor(0.4281)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.6299)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.2754)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.5117)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.3770)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.4281)\n",
      "['Sliced', 'Meat']\n",
      "tensor(0.6299)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.2754)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.5117)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.3768)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.4984)\n",
      "['Seasoned', 'Carrot']\n",
      "tensor(0.4319)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.6248)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.2720)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.3768)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.4984)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.4319)\n",
      "['Sliced', 'Meat']\n",
      "tensor(0.6248)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.2720)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.5009)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.5967)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.7236)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.3783)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(1.00000e-02 *\n",
      "       8.9493)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.5921)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.5009)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.5967)\n",
      "['Sliced', 'Meat']\n",
      "tensor(0.7236)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.3783)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(1.00000e-02 *\n",
      "       8.9493)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.5921)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.2511)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.3644)\n",
      "['Seasoned', 'Carrot']\n",
      "tensor(0.2822)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.1439)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Seasoned', 'Apple']\n",
      "tensor(0.3582)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.2511)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.3644)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.2822)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.1439)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(0.)\n",
      "['Sliced', 'Apple']\n",
      "tensor(0.3582)\n",
      "['Seasoned', 'Onion']\n",
      "tensor(0.4166)\n",
      "['Seasoned', 'Potato']\n",
      "tensor(0.5219)\n",
      "['Seasoned', 'Carrot']\n",
      "tensor(0.4358)\n",
      "['Seasoned', 'Meat']\n",
      "tensor(0.6364)\n",
      "['Seasoned', 'Eggs']\n",
      "tensor(0.2783)\n",
      "['Seasoned', 'Cauliflower']\n",
      "tensor(1.00000e-03 *\n",
      "       6.7983)\n",
      "['Sliced', 'Onion']\n",
      "tensor(0.4166)\n",
      "['Sliced', 'Potato']\n",
      "tensor(0.5219)\n",
      "['Sliced', 'Carrot']\n",
      "tensor(0.4358)\n",
      "['Sliced', 'Meat']\n",
      "tensor(0.6364)\n",
      "['Sliced', 'Eggs']\n",
      "tensor(0.2783)\n",
      "['Sliced', 'Cauliflower']\n",
      "tensor(1.00000e-03 *\n",
      "       6.7983)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 11\n",
    "for op in operators: # for each operator...\n",
    "    class_names = image_datasets[op].classes\n",
    "    imgs = []\n",
    "    pp = []\n",
    "    np = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    while len(imgs) < batch_size:\n",
    "        inputs, classes = next(iter(dataloaders[op]))  # Gather a set of images and classes from them\n",
    "        \n",
    "        for i in inputs:\n",
    "            imgs.append(feat_extractor(i.unsqueeze_(0)))\n",
    "            if(len(imgs) == batch_size):\n",
    "                break\n",
    "        for i in classes:\n",
    "            pp.append([op, class_names[i]])\n",
    "            if(len(pp) == batch_size):\n",
    "                break\n",
    "\n",
    "    np = get_neg_pairs(pp)\n",
    "    for i in range(len(imgs)):\n",
    "        for j in np[i]:\n",
    "            model.train_forward(imgs[i], pp[i][1], pp[i][0], j[1], j[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inApple = []\n",
    "while len(inApple) < 5:\n",
    "    inputs, classes = next(iter(dataloaders['Whole']))\n",
    "    #print(classes)\n",
    "    #print(classes.data[0])\n",
    "    for i in range(len(inputs)):\n",
    "        if classes.data[i] == 0:\n",
    "            inApple.append(inputs[i])\n",
    "#print(inApple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = [] # Apple Features\n",
    "for i in range(len(inApple)):\n",
    "    af.append(feat_extractor(inApple[i].unsqueeze_(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
