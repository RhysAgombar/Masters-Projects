{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "from io import open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIFile = open(\"WI.pickle\",\"rb\")\n",
    "word_indices = pickle.load(WIFile)\n",
    "\n",
    "gramFile = open(\"QG.pickle\",\"rb\")\n",
    "quatragrams = pickle.load(gramFile)\n",
    "\n",
    "emFile = open(\"Em.pickle\",\"rb\")\n",
    "embeddings = pickle.load(emFile)\n",
    "\n",
    "vFile = open(\"Vocab.pickle\",\"rb\")\n",
    "vocab = pickle.load(vFile)\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    embeddings[i] = embeddings[i].view(1,len(embeddings[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 3\n",
    "EMBEDDING_DIM = 50\n",
    "VOCAB_LEN = len(word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(CONTEXT_SIZE*embedding_dim + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(CONTEXT_SIZE*embedding_dim + hidden_size, EMBEDDING_DIM)\n",
    "        self.i2o2 = nn.Linear(EMBEDDING_DIM, VOCAB_LEN)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.i2o2(output)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "n_hidden = 128\n",
    "rn = RNN(VOCAB_LEN, n_hidden, EMBEDDING_DIM)\n",
    "optimizer = optim.SGD(rn.parameters(), lr=0.01)\n",
    "loss_function = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "[38507.21, 33700.611, 31413.142, 29538.134, 27909.615, 26491.437, 25269.952, 24231.293, 23365.909, 22658.578]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    if (epoch % 1 == 0):\n",
    "        print(\"Epoch: \", epoch)\n",
    "    total_loss = 0\n",
    "    hidden = rn.initHidden()\n",
    "    for context, target in quatragrams:\n",
    "\n",
    "        one = word_indices[context[0]]\n",
    "        two = word_indices[context[1]]\n",
    "        three = word_indices[context[2]]\n",
    "        target = word_indices[target]\n",
    "\n",
    "    \n",
    "        cat = torch.cat((embeddings[one], embeddings[two], embeddings[three]), 1)\n",
    "        context_idxs = cat\n",
    "\n",
    "        rn.zero_grad()\n",
    "\n",
    "        out, hidden = rn(context_idxs, hidden)\n",
    "        \n",
    "        loss = loss_function(out, torch.tensor([target], dtype=torch.long))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        hidden.detach_()\n",
    "    losses.append(round(total_loss, 3))\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-02 *\n",
      "       -8.9979) tensor(1141)\n",
      "cashew_nuts\n"
     ]
    }
   ],
   "source": [
    "one = word_indices[\"preheat\"]\n",
    "two = word_indices[\"the\"]\n",
    "three = word_indices[\"oven\"]\n",
    "\n",
    "\n",
    "cat = torch.cat((embeddings[one], embeddings[two], embeddings[three]), 1)\n",
    "context_idxs = cat\n",
    "\n",
    "out, hidden = rn(context_idxs, hidden)\n",
    "\n",
    "out = out[0]\n",
    "values, indices = out.max(0)\n",
    "print(values, indices)\n",
    "print(list(vocab)[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['combine', 'the', 'cashew_nuts', 'cashew_nuts', 'spoonfuls', 'pour', 'cashew_nuts', 'parmesan', 'pour', 'baking', 'servingssuggested', 'cashew_nuts', 'spoonfuls', 'pour', 'cashew_nuts', 'parmesan', 'pour', 'baking', 'servingssuggested', 'cashew_nuts', 'spoonfuls', 'pour', 'cashew_nuts', 'parmesan', 'pour', 'baking', 'servingssuggested', 'cashew_nuts', 'spoonfuls', 'pour', 'cashew_nuts', 'parmesan', 'pour', 'baking', 'servingssuggested', 'cashew_nuts', 'spoonfuls', 'pour', 'cashew_nuts', 'parmesan', 'pour', 'baking', 'servingssuggested', 'cashew_nuts', 'spoonfuls', 'pour', 'cashew_nuts', 'parmesan', 'pour', 'baking', 'servingssuggested', 'cashew_nuts', 'spoonfuls', 'pour', 'cashew_nuts', 'parmesan', 'pour', 'baking', 'servingssuggested', 'cashew_nuts', 'spoonfuls', 'pour', 'cashew_nuts', 'parmesan', 'pour', 'baking', 'servingssuggested', 'cashew_nuts', 'spoonfuls', 'pour', 'cashew_nuts', 'parmesan', 'pour', 'baking', 'servingssuggested', 'cashew_nuts', 'spoonfuls', 'pour', 'cashew_nuts', 'parmesan', 'pour', 'baking', 'servingssuggested', 'cashew_nuts', 'spoonfuls', 'pour', 'cashew_nuts', 'parmesan', 'pour', 'baking', 'servingssuggested', 'cashew_nuts', 'spoonfuls', 'pour', 'cashew_nuts', 'parmesan', 'pour', 'baking', 'servingssuggested', 'cashew_nuts', 'spoonfuls', 'pour']\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"combine\", \"the\"]\n",
    "for j in range(0,100):\n",
    "\n",
    "    two = word_indices[sentence[-1]]\n",
    "    one = word_indices[sentence[-2]]\n",
    "    \n",
    "    cat = torch.cat((embeddings[one], embeddings[two], embeddings[three]), 1)\n",
    "    context_idxs = cat\n",
    "\n",
    "    out, hidden = rn(context_idxs, hidden)\n",
    "\n",
    "    out = out[0]\n",
    "    values, indices = out.max(0)\n",
    "    \n",
    "    sentence.append(list(vocab)[indices])\n",
    "\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
